{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>duration</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>79</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services</td>\n",
       "      <td>220</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>management</td>\n",
       "      <td>185</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>management</td>\n",
       "      <td>199</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>226</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job  duration poutcome\n",
       "0   unemployed        79  unknown\n",
       "1     services       220  failure\n",
       "2   management       185  failure\n",
       "3   management       199  unknown\n",
       "4  blue-collar       226  unknown"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset used to train the model\n",
    "df = pd.read_csv(\"Data/bank.csv\")\n",
    "features = ['job', 'duration', 'poutcome']\n",
    "df = df[features] \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing virtual environment with Pipenv\n",
    "\n",
    "Pipenv permits us to create a virtual environment to isolate your project dependencies, ensuring that packages installed for one project don't interfere with other projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It provides an integrated environment for managing both project dependencies and the Python runtime environment. It combines the functionality of pip (Python's package installer) and virtualenv (a tool for creating isolated Python environments).\n",
    "\n",
    "`Terminal`\n",
    "---\n",
    "----\n",
    "```bash\n",
    "marcos@marcos:~$ pip install pipenv\n",
    "marcos@marcos:~$ pipenv --version\n",
    "marcos@marcos:~$ pipenv, version 2023.10.3\n",
    "```\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install Python packages in an isolated virtual environment I first navigate to the specific project directory. After that, I create an empty folder and execute the package installation command.\n",
    "\n",
    "`Terminal`\n",
    "---\n",
    "-----\n",
    "\n",
    "```bash\n",
    "marcos@marcos:~$ cd /GitHub/ML_Zoomcamp/05Deploy/Homework\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ mkdir Homework\n",
    "marcos@marcos:~$ pipenv install Scikit-Learn==1.3.1\n",
    "```\n",
    "\n",
    "```\n",
    "Output -------------\n",
    "Updated Pipfile.lock (0e0fec5cb0e411bbb2c1c4f81b061609272a25d0c1f780d06dd30aff281bed02)\n",
    "To activate this project's virtualenv, run pipenv shell.\n",
    "Alternatively, run a command inside the virtualenv with pipenv run.\n",
    "```\n",
    "-----\n",
    "\n",
    "- `Pipfile`: list of libraries and version of Python used\n",
    "\n",
    "- `Pipfile.lock`: Contains the specific versions of the libraries that we used for the project.\n",
    "\n",
    "The hash value associated with the current `Pipfile.lock` serves a similar function to Git commit hashes.\n",
    "\n",
    "- Hash `pipfile.lock`: `0e0fec5cb0e411bbb2c1c4f81b061609272a25d0c1f780d06dd30aff281bed02`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job','duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/model1.bin?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using  `wget`,  we downloaded the two files: the **pre-trained model** (`model1.bin`) and the **vectorized dictionary** (`dv.bin`).\n",
    "\n",
    "`Terminal`\n",
    "---\n",
    "------\n",
    "```bash\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ wget $PREFIX/model1.bin\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ wget $PREFIX/dv.bin\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ ls\n",
    "$ dv.bin  model1.bin  Pipfile  Pipfile.lock\n",
    "```\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model with Pickle\n",
    "\n",
    "Pickle allows for the serialization of Python objects, enabling you to save and load machine learning models. With Pickle, we can store a trained model into a binary file and later reload it to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of loading a pre-trained model and utilizing it to predict credit eligibility for a single customer is described in the following diagram:\n",
    "\n",
    "<center><img src = \"Images/model_service.png\" width=\"700\" height=\"400\"/></center>\n",
    "\n",
    "First, let's create a simple Python script that loads the existing model and utilizes it to make a prediction for a single customer. This script is saved in the Homework/question3.py folder. Inside this Python file, we have:\n",
    "\n",
    "`question3.py`\n",
    "---\n",
    "\n",
    "----\n",
    "```python\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Preditiction for a single customer\n",
    "def single_pred(customer, dv, model):\n",
    "    X = dv.transform([customer])\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred[0]\n",
    "\n",
    "# Paths\n",
    "filepath_dv = 'dv.bin'\n",
    "filepath_model = 'model1.bin'\n",
    "\n",
    "# Load dictionary vectorizer\n",
    "if os.path.exists(filepath_dv):\n",
    "    with open(filepath_dv, 'rb') as f_dv:\n",
    "        dv = pickle.load(f_dv)\n",
    "else:\n",
    "    print(f\"File {filepath_dv} not found.\")\n",
    "\n",
    "# Load model\n",
    "if os.path.exists(filepath_model):\n",
    "    with open(filepath_model, 'rb') as f_model:\n",
    "        model = pickle.load(f_model)\n",
    "else:\n",
    "    print(f\"File {filepath_model} not found.\")\n",
    "\n",
    "customer = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "pred = single_pred(customer, dv, model)\n",
    "\n",
    "print('prediction: %.3f' % pred)\n",
    "if pred >= 0.5:\n",
    "    print('Get Credit: High')\n",
    "else:\n",
    "    print('Get Credit: Low')\n",
    "```\n",
    "------------\n",
    "\n",
    "\n",
    "With the script ready, let's activate the virtual environment and execute the script in the terminal, therefore isolating the required dependencies to run the script.\n",
    "\n",
    "`Terminal`\n",
    "---\n",
    "------\n",
    "```bash\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ pipenv shell\n",
    "Launching subshell in virtual environment...\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$  . /home/marcos/.local/share/virtualenvs/Homework-zL5dlJ2M/bin/activate\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$  python question3.py\n",
    "\n",
    "\n",
    "$ prediction: 0.902\n",
    "$ Get Credit: High\n",
    "```\n",
    "-------\n",
    "\n",
    "then we can exit the virtual environment with `$ exit`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model in Web service with Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "customer = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=customer).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question4.py`\n",
    "---\n",
    "\n",
    "------\n",
    "```python\n",
    "import pickle\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# request: To get the content of a POST request\n",
    "# jsonsify: To respond with JSON (dictionary)\n",
    "\n",
    "# Preditiction for a single customer\n",
    "def single_pred(customer, dv, model):\n",
    "    X = dv.transform([customer])\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred[0]\n",
    "\n",
    "\n",
    "# Paths\n",
    "filepath_dv = 'dv.bin'\n",
    "filepath_model = 'model1.bin'\n",
    "\n",
    "# Load dictionary vectorizer\n",
    "if os.path.exists(filepath_dv):\n",
    "    with open(filepath_dv, 'rb') as f_dv:\n",
    "        dv = pickle.load(f_dv)\n",
    "else:\n",
    "    print(f\"File {filepath_dv} not found.\")\n",
    "\n",
    "# Load model\n",
    "if os.path.exists(filepath_model):\n",
    "    with open(filepath_model, 'rb') as f_model:\n",
    "        model = pickle.load(f_model)\n",
    "else:\n",
    "    print(f\"File {filepath_model} not found.\")\n",
    "\n",
    "app = Flask('churn')\n",
    "# Registers the /predict route, and assigns it to the predict function\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    customer =  request.get_json()\n",
    "    pred = single_pred(customer, dv, model)\n",
    "    result = {'Credit probability': float(pred)}\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #To test it, open the browser and type 'localhost:9696/predict'\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "```\n",
    "----\n",
    "\n",
    "To run the web service, we run the Python file. This starts the Flask web service, making it accessible at `http://127.0.0.1:9696.`\n",
    "\n",
    "`Terminal`\n",
    "---\n",
    "----\n",
    "```bash\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ python3 question4.py\n",
    " * Running on all addresses (0.0.0.0)\n",
    " * Running on http://127.0.0.1:9696\n",
    " * Running on http://192.168.1.64:9696\n",
    "\n",
    "```\n",
    "----\n",
    "\n",
    "Once the web service is running, is possible to use HTTP POST requests to predict the credit probability for a given customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit probability': 0.13968947052356817}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:9696/predict\"\n",
    "customer = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json = customer).json()\n",
    "\n",
    "# Output: {'Credit probability': 0.13968947052356817}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "Docker solves the problem with environment inconsistencies, by creating an isolated application called container, with Python dependencies, the operating system, and system libraries. This ensures uniform behavior across diverse operation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src = \"Images/docker.png\" width=\"700\" height=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base image: `svizor/zoomcamp-model:3.10.12-slim`. \n",
    "\n",
    "This image is based on `python:3.10.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "`Dockerfile`\n",
    "---\n",
    "----\n",
    "```docker \n",
    "FROM python:3.10.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "----\n",
    "\n",
    "The Dockerfile is a script containing commands that creates a snapshot of our application along with its dependencies, environment settings. To create a Docker image from the Dockerfile we run the Dockerfile, executing each command line-by-line with `docker build -t your-image-name`.\n",
    "\n",
    "The image here was already built it and then pushed it to [`svizor/zoomcamp-model:3.10.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.10.12-slim` by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`Terminal`\n",
    "----\n",
    "----\n",
    "```bash\n",
    "marcos@marcos:~$ sudo docker pull svizor/zoomcamp-model:3.10.12-slim\n",
    "marcos@marcos:~$ sudo docker images\n",
    "$ REPOSITORY              TAG            IMAGE ID       CREATED      SIZE\n",
    "$ svizor/zoomcamp-model   3.10.12-slim   08266c8f0c4b   6 days ago   147MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "`Dockerfile`\n",
    "---\n",
    "\n",
    "-----\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "----\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Dockerfile`\n",
    "---\n",
    "\n",
    "----\n",
    "```docker\n",
    "\n",
    "# Start with the existing image as a base\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "\n",
    "# Set environment variables\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "# Install pipenv\n",
    "RUN pip --no-cache-dir install pipenv\n",
    "\n",
    "# Set the working directory inside the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy Pipenv files into the container\n",
    "COPY [\"Pipfile\", \"Pipfile.lock\", \"./\"]\n",
    "\n",
    "# Install Python dependencies\n",
    "RUN pipenv install --deploy --system\n",
    "\n",
    "# Copy the Flask script into the container\n",
    "COPY [\"your_flask_script.py\", \"./\"]\n",
    "\n",
    "# Expose the port the app runs on\n",
    "EXPOSE 9696\n",
    "\n",
    "# Run Gunicorn\n",
    "ENTRYPOINT [\"gunicorn\", \"--bind\", \"0.0.0.0:9696\", \"your_flask_script:app\"]\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "Once the image is built, we can run it using `docker run -p 9696:9696 your-image-name`. Here we will only downloaded the base image to run the application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
