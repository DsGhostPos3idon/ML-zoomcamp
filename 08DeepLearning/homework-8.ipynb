{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Layer, Conv2D, MaxPool2D, Flatten\n",
    "from keras.losses import Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# **Convolutional Neural Networks (CNNs) - Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (CNN) is essentially a feedforward Multi-Layer Perceptron (MLP) that is designed to recognize local patterns and sparsity in input data. Like the MLP, each neuron is connected to others through learnable weights. These weights are adjusted during training to optimize the network's performance for a specific task.\n",
    "\n",
    "The main difference between MLPs and CNNs is that the latter is developed for processing multidimensional data, such as images or videos. Also, CNNs have a more diverse set of specialized layers, including convolutional layers, pooling layers, and upsampling layers, which are optimized for processing spatial (image) and temporal data (video)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convolutions**\n",
    "\n",
    "Convolution is a mathematical operation that involves sliding a small matrix, known as a kernel or filter, across a larger matrix representing the input data, such as an image. During this process, the element-wise product $\\odot$ is computed between the kernel and each local region (sub-matrix) it covers on the input data matrix. The result of this operation is a new matrix, called a feature map, which encodes information about the presence, absence, or strength of specific features in the input data.\n",
    "\n",
    "Let's examine the following convolutional operations to illustrate this concept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **One Dimension**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider $\\mathbf{x}$ as an input vector with $n$ elements and $\\mathbf{w}$ as a weight vector, also known as a  **filter**, with $k \\leq n$.\n",
    "\n",
    "$$\n",
    "\\mathbf{x} =\n",
    "\\left( \\begin{array}{c}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{array} \\right), ~~~~\n",
    "\\mathbf{w} =\n",
    "\\left( \\begin{array}{c}\n",
    "w_{1}\\\\\n",
    "w_{2}\\\\\n",
    "\\vdots\\\\\n",
    "w_{k}\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Here $k$  is known as the  **window size** and indicates the size of the filter applied to the input vector $\\mathbf{x}$. It defines the region of the local neighborhood within the input vector $\\mathbf{x}$ used for computing output values. To proceed, we define a subvector of $\\mathbf{x}$ with the same size as the filter vector. Let $\\mathbf{x}_k(i)$ denote the window of $\\mathbf{x}$  of size $k$ starting at position $i$:\n",
    "\n",
    "$$\\mathbf{x}_k(i) = \\left( \\begin{array}{c}\n",
    "x_i \\\\\n",
    "x_{i+1} \\\\\n",
    "\\vdots\\\\\n",
    "x_{i+k-1} \n",
    "\\end{array} \\right).$$\n",
    "\n",
    "For $k \\leq n$, it must be that $i+k-1 \\leq n$, implying $1 \\leq i \\leq n-k+1$. As a validity test, if we start at $i =  n-k+1$, then the end position is $i+k-1 = n$. If we calculate the total number of elements by the difference in position provides the window size $k$, confirmed by $n - i = n - (n-k+1) = k$. For example, with $n = 5$ and $k = 3$:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} =\n",
    "\\left( \\begin{array}{c}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "x_{3}\\\\\n",
    "x_{4}\\\\\n",
    "x_{5}\n",
    "\\end{array} \\right), ~~~~\n",
    "\\mathbf{w} =\n",
    "\\left( \\begin{array}{c}\n",
    "w_{1}\\\\\n",
    "w_{2}\\\\\n",
    "w_{3}\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "the window of $\\mathbf{x}$ from $i = 2$ to $i+k-1 = 4$ is:\n",
    "\n",
    "$$\\mathbf{x}_3(2) = \\left( \\begin{array}{c}\n",
    "x_2 \\\\\n",
    "x_{3}\\\\\n",
    "x_{4}\n",
    "\\end{array} \\right)$$\n",
    "\n",
    "**Example**\n",
    "\n",
    "Let's first consider a particular example with input vector $\\mathbf{x}$ of size $n = 5$ and a weight vector with window size $k = 3$. The vectors are illustrated in the following figure:\n",
    "\n",
    "<center><img src = \"figures/1d-conv.png\" width=\"800\" height=\"400\"/></center>\n",
    "\n",
    "\n",
    "The convolution steps for the sliding windows of $\\mathbf{x}$ with the filter $\\mathbf{w}$ are:\n",
    "\n",
    "\n",
    "$$\n",
    "\\sum \\mathbf{x}_3(1) \\odot \\mathbf{w} = \\sum (1, 3, -1)^T \\odot (1, 0, 2)^T = \\sum  (1 \\cdot 1, 3 \\cdot 0, -1 \\cdot 2) = 1 + 0 - 2 = -1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum \\mathbf{x}_3(2) \\odot \\mathbf{w} = \\sum (3, -1, 2)^T \\odot (1, 0, 2)^T = \\sum  (3 \\cdot 1, -1 \\cdot 0, 2 \\cdot 2) = 3 + 0 + 4 = 7,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum \\mathbf{x}_3(3) \\odot \\mathbf{w} = \\sum (-1, 2, 3)^T \\odot (1, 0, 2)^T = \\sum  (-1 \\cdot 1, 2 \\cdot 0, 3 \\cdot 2) = -1 + 0 + 6 = 5.\n",
    "$$\n",
    "\n",
    "The element-wise product $\\odot$  , also known as the Hadamard product, multiplies corresponding elements in two vectors. Unlike the typical inner product, which multiplies an element by a column, this operation multiplies an element by its corresponding element in another vector. This steps provide the convolution between the two vectors resulting in a vector of size n-k+1 = 3. Thus, the convolution $\\mathbf{x} * \\mathbf{w}$ is:\n",
    "\n",
    "$$\\mathbf{x} * \\mathbf{w} =\n",
    "\\left( \\begin{array}{c}\n",
    "-1\\\\\n",
    "7\\\\\n",
    "5\n",
    "\\end{array} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector X: (5,)\n",
      "filter W: (3,)\n",
      "output X*W: [-1  7  5]\n"
     ]
    }
   ],
   "source": [
    "# Code for the example\n",
    "\n",
    "X = np.array([1, 3, -1, 2, 3])\n",
    "# flip the filter W to use the convolve function\n",
    "# as expected in machine learning and deep learning context\n",
    "W = np.flip(np.array([1, 0, 2]))\n",
    "\n",
    "# perform 1D convolution\n",
    "output = np.convolve(X, W, mode='valid')\n",
    "\n",
    "print(\"Input vector X:\", X.shape)\n",
    "print(\"filter W:\", W.shape)\n",
    "print(\"output X*W:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates that convolution is an element-wise product between a subvector and a weight vector of the same size, providing a scalar value when summed, which forms the result of the convolution operation.\n",
    "\n",
    "To simplify the notation, let's adopt the convention that for a vector $\\mathbf{a} \\in \\mathbb{R}^k$, define the summation operator as one that adds all elements of the vector. That is, \n",
    "\n",
    "$$\\text{Sum}(\\mathbf{a}) = \\sum_{i=1}^{k} a_{i}$$ \n",
    "\n",
    "Then from the example, we would have\n",
    "\n",
    "$$\n",
    "\\sum \\mathbf{x}_3(1) \\odot \\mathbf{w} = \\text{Sum}\\bigg( \\mathbf{x}_3(1) \\odot \\mathbf{w} \\bigg)= 1 + 0 - 2 = -1.\n",
    "$$\n",
    "\n",
    "Then, we can define a general one dimensional convolution operation between $\\mathbf{x}$ and $\\mathbf{w}$, denoted by the asterisk symbol $\\ast$, as \n",
    "\n",
    "$$\\mathbf{x} \\ast \\mathbf{w} = \\left( \\begin{array}{c}\n",
    "\\text{Sum}(\\mathbf{x}_k(1) \\odot \\mathbf{w})\\\\\n",
    "\\vdots\\\\\n",
    "\\text{Sum}(\\mathbf{x}_k(i) \\odot \\mathbf{w})\\\\\n",
    "\\vdots\\\\\n",
    "\\text{Sum}(\\mathbf{x}_k(n-k+1) \\odot \\mathbf{w})\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "The convolution of $\\mathbf{x} \\in \\mathbf{R}^{n}$ and $\\mathbf{W} \\in \\mathbf{R}^{k}$ results in a vector of size $n-k+1$. The i-th element from this output vector can be decomposed as\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{x_k}(i) \\odot \\mathbf{w}) = x_{i}w_1 + x_{i+1}w_2 + \\cdots + x_{(i+k-1)}w_k =  \\sum_{j=1}^{k} x_{(i+j-1)}w_j.$$\n",
    "\n",
    "This shows that the sum is over all elements of the subvector $\\mathbf{x}_k(i)$, so the last element of this sum must coincide with the last elements of $\\mathbf{x}_k(i)$ and $\\mathbf{w}$. This results in the convolution of $\\mathbf{x}$ with $\\mathbf{w}$ over the window defined by $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Two Dimension**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the convolution operation to an matrix input instead of a vector. Let $\\mathbf{X}$ be an input matrix with $n \\times n$ elements and $\\mathbf{W}$ be the weight matrix, also known as a  **filter**, with $k \\leq n$.\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1} & x_{n,2} & \\cdots & x_{n,n}\n",
    "\\end{bmatrix},~~\n",
    "\\mathbf{W}=\\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\cdots & w_{1,k} \\\\\n",
    "w_{2,1} & w_{2,2} & \\cdots & w_{2,k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{k,1} & w_{k,2} & \\cdots & w_{k,k}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Here, similar to the one dimensional case,  $k$ is the window size and indicates the size of the filter applied to the input matrix $\\mathbf{X}$. From the one dimensional case we can extend the notion of a sub vector to a sub matrix. Let $\\mathbf{X}_k(i,j)$ denote the $k \\times k$ submatrix of $\\mathbf{X}$ starting at row $i$ and column $j$ as\n",
    "\n",
    "$$\\mathbf{X}_k(i,j) = \\begin{bmatrix}\n",
    "x_{i,j} & x_{i,~(j+1)} & \\cdots & x_{i,~(j+k-1)} \\\\\n",
    "x_{(i+1),~j} & x_{(i+2),~j} & \\cdots & x_{(i+1), (j+k-1)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{(i+k-1), ~j} & x_{(i+1),(j+1)} & \\cdots & x_{(i+k-1),(j+k-1)}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where for two indices, give that this is a square matrix, the range is simple $1 \\leq (i,j) \\leq n-k+1$.\n",
    "\n",
    "As for the one dimensional case, to simplify the notation, we adopt the convention that for a matrix $\\mathbf{A} \\in \\mathbb{R}^{k \\times k}$ define the summation operator as one that adds all elements of the matrix.\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{A}) = \\sum_{i=1}^{k}\\sum_{j=1}^{k} a_{i,j}$$\n",
    "\n",
    "Then, we can define  a general two dimensional convolution operation between matrices $\\mathbf{X}$ and $\\mathbf{W}$, as\n",
    "\n",
    "\n",
    "$$\\mathbf{X} \\ast \\mathbf{W} = \\begin{bmatrix}\n",
    "\\text{Sum}(x_k(1,1) \\odot \\mathbf{W}) &\\text{Sum}(x_k(1,2) \\odot \\mathbf{W}) & \\cdots & \\text{Sum}(x_k(1,n-k+1) \\odot \\mathbf{W}) \\\\\n",
    "\\text{Sum}(x_k(2,1) \\odot \\mathbf{W}) & \\text{Sum}(x_k(2,2) \\odot \\mathbf{W}) & \\cdots &\\text{Sum}(x_k(2,n-k+1) \\odot \\mathbf{W})\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Sum}(x_k(n-k+1,1) \\odot \\mathbf{W}) & \\text{Sum}(x_k(n-k+1,2) \\odot \\mathbf{W}) & \\cdots & \\text{Sum}(x_k(n-k+1,n-k+1) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{X}_k(i,j) \\odot \\mathbf{W})=\\sum_{a=1}^{k}\\sum_{b=1}^{k} x_{(i+a-1),(j+b-1)} w_{a,b}$$\n",
    "\n",
    "The convolution of $\\mathbf{X} \\in \\mathbf{R}^{n \\times n}$ and $\\mathbf{W} \\in \\mathbf{R}^{k \\times k}$ results in a $(n-k+1) \\times (n-k+1)$ matrix.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Let's consider a particular example with input matrix $\\mathbf{X}$ with dimension  $3 \\times 3$ (n = 3) and a weight matrix with dimension  $2 \\times 2$ (k = 2). The matrices are illustrated in the following figure:\n",
    "\n",
    "<center><img src = \"figures/2d-conv.png\" width=\"800\" height=\"400\"/></center>\n",
    "\n",
    "The convolution steps for the sliding windows of $\\mathbf{X}$ with the filter $\\mathbf{W}$ illustrated in the figure are mathematically translated to:\n",
    "\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{X}_k(1,1) \\odot \\mathbf{W})=\\text{Sum}\\bigg(\n",
    "    \\begin{bmatrix} \n",
    "    1 & 2 \\\\\n",
    "    3 & 1 \n",
    "    \\end{bmatrix} \n",
    "    \\odot \n",
    "    \\begin{bmatrix} \n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "    \\end{bmatrix} \\bigg) =  2$$\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{X}_2(1,2) \\odot \\mathbf{W}) = \\text{Sum}\\bigg(\n",
    "    \\begin{bmatrix} \n",
    "    2 & 2 \\\\\n",
    "    1 & 4\n",
    "    \\end{bmatrix} \n",
    "    \\odot\n",
    "    \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "    \\end{bmatrix} \\bigg)= 6$$\n",
    "\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{X}_2(2,1) \\odot \\mathbf{W}) = \\text{Sum}\\bigg( \n",
    "    \\begin{bmatrix} \n",
    "    3 & 1 \\\\ \n",
    "    2 & 1 \\end{bmatrix} \n",
    "    \\odot \\begin{bmatrix} \n",
    "    1 & 0 \\\\ \n",
    "    0 & 1 \n",
    "    \\end{bmatrix} \\bigg)= 4$$\n",
    "\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{X}_2(2,2) \\odot \\mathbf{W}) = \\text{Sum}\\bigg( \n",
    "    \\begin{bmatrix} \n",
    "    1 & 4 \\\\\n",
    "    3 & 3 \\end{bmatrix}\n",
    "    \\odot\n",
    "    \\begin{bmatrix}\n",
    "    1 & 0 \\\\ \n",
    "    0 & 1\n",
    "    \\end{bmatrix} \\bigg) = 4$$\n",
    "\n",
    "The convolution $\\mathbf{X}*\\mathbf{W}$ has size $2 \\times 2$, since  $n - k + 1 = 3 - 2 + 1 = 2$, and is given by\n",
    "\n",
    "$$\\mathbf{X}*\\mathbf{W} = \n",
    "    \\begin{bmatrix} \n",
    "        \\text{Sum}(\\mathbf{X}_2(1,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{X}_2(1,2) \\odot \\mathbf{W}) \\\\\n",
    "        \\\\\n",
    "        \\text{Sum}(\\mathbf{X}_2(2,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{X}_2(2,2) \\odot \\mathbf{W}) \n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix} \n",
    "        2 & 6 \\\\\n",
    "        4 & 4 \n",
    "    \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Three dimensional Convolution on CNNs**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extend the convolution operation to a three-dimensional matrix, also called a rank-3 tensor. The first dimension comprises the rows (height), second dimension the columns (width) and the third dimension the channels (number of 2D slices stacked along the depth axis). Typically in CNNs, we use a 3D filter $\\mathbf{W} \\in \\mathbb{R}^{k \\times k \\times m}$, with the number of channels equal to the number of channels of the input tensor $\\mathbf{X} \\in \\mathbb{R}^{n \\times n \\times m}$, in this case with $m$ channels each. Mathematically we represent as:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}=\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{1,1,1} & x_{1,2,1} & \\cdots & x_{1,n,1} \\\\\n",
    "x_{2,1,1} & x_{2,2,1} & \\cdots & x_{2,n,1} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1,1} & x_{n,2,1} & \\cdots & x_{n,n,1}\n",
    "\\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "x_{1,1,2} & x_{1,2,2} & \\cdots & x_{1,n,2} \\\\\n",
    "x_{2,1,2} & x_{2,2,2} & \\cdots & x_{2,n,2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1,2} & x_{n,2,2} & \\cdots & x_{n,n,2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\vdots\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "x_{1,1,m} & x_{1,2,m} & \\cdots & x_{1,n,m} \\\\\n",
    "x_{2,1,m} & x_{2,2,m} & \\cdots & x_{2,n,m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n,1,m} & x_{n,2,m} & \\cdots & x_{n,n,m}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix},~~\n",
    "\n",
    "\n",
    "\\mathbf{W}= \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_{1,1,1} & w_{1,2,1} & \\cdots & w_{1,k,1} \\\\\n",
    "w_{2,1,1} & w_{2,2,1} & \\cdots & w_{2,k,1} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{k,1,1} & w_{k,2,1} & \\cdots & w_{k,k,1}\n",
    "\\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "w_{1,1,2} & w_{1,2,2} & \\cdots & w_{1,k,2} \\\\\n",
    "w_{2,1,2} & w_{2,2,2} & \\cdots & w_{2,k,2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{k,1,2} & w_{k,2,2} & \\cdots & w_{k,k,2}\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\vdots\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "w_{1,1,r} & w_{1,2,r} & \\cdots & w_{1,k,m} \\\\\n",
    "w_{2,1,r} & w_{2,2,r} & \\cdots & w_{2,k,m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{k,1,r} & w_{k,2,r} & \\cdots & w_{k,k,m}\n",
    "\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Similar to convolutions in other dimensions, the window size must satisfy $k \\leq n$, and the total number of slice matrices along the depth of the filter and input tensor are fixed as $m$. This mathematical representation of a tensor may seem complex at first, but it closely resembles how Python libraries like NumPy represent a tensor, with exception of the order of rows, columns and depth.\n",
    "\n",
    "When defining a sub-tensor from the input tensor $\\mathbf{X}$, let $\\mathbf{X}_k(i,j)$ denote a $k \\times k \\times m$ sub-tensor of $\\mathbf{X}$ that starts at row $i$, column $j$, and encompasses the full depth $m$ of the input. In the context where the filter spans the entire depth of the input (i.e., the number of channels $r$ in the filter is equal to the depth $m$ of the input), the depth index $q$ is not needed because the filter processes all depth layers simultaneously. Therefore, the sub-tensor $\\mathbf{X}_k(i,j)$ is defined as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{X}_k(i,j,q = m)= \\mathbf{X}_k(i,j) =\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{i,j,1} & x_{i,(j+1),1} & \\cdots & x_{i,(j+k-1),1} \\\\\n",
    "x_{(i+1),j,1} & x_{(i+1),(j+1),1} & \\cdots & x_{(i+1),(j+k-1),1} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{(i+k-1),j,1} & x_{(i+k-1),(j+1),1} & \\cdots & x_{(i+k-1),(j+k-1),1}\n",
    "\\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "x_{i,j,2} & x_{i,(j+1),2} & \\cdots & x_{i,(j+k-1),2} \\\\\n",
    "x_{(i+1),j,2} & x_{(i+1),(j+1),2} & \\cdots & x_{(i+1),(j+k-1),2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{(i+k-1),j,2} & x_{(i+k-1),(j+1),2} & \\cdots & x_{(i+k-1),(j+k-1),2}\n",
    "\\end{bmatrix}\\\\\n",
    "\\\\\n",
    "\\vdots\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "x_{i,j,m} & x_{i,(j+1),m} & \\cdots & x_{i,(j+k-1),m} \\\\\n",
    "x_{(i+1),j,m} & x_{(i+1),(j+1),m} & \\cdots & x_{2,n,m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{(i+k-1),j,m} & x_{(i+k-1),(j+1),m} & \\cdots & x_{(i+k-1),(j+k-1),m}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The indices from the subtensor for rows and columns range from $1 \\leq (i,j) \\leq n-k+1$, where $n$ is the dimension of the input $\\mathbf{X}$ and $k$ is the window size of the filter $\\mathbf{W}$, consistent with two-dimensional convolutions. The depth dimension is fixed at $m$, so it's redundant carrying $q = m$ in our notation. \n",
    "\n",
    "As in the case of convolution in lower dimensions, we define the summation operator as one that adds all elements within the tensor. Therefore, given a tensor $\\mathbf{A} \\in \\mathbb{R}^{k \\times k \\times m}$, the summation operation is defined as:\n",
    "\n",
    "$$\\text{Sum}(\\mathbf{A}) = \\sum_{a=1}^{k}\\sum_{b=1}^{k}\\sum_{q=1}^{m}a_{ijq}$$\n",
    "\n",
    "This summation adds up all the elements in the tensor $\\mathbf{A}$, where $a_{ijq}$ denotes the element located at the $i$-th row, $j$-th column, and $q$-th depth layer.\n",
    "\n",
    "\n",
    "Before we generalize the convolution operation to three dimensions, let's consider an example to illustrate the logic behind this mathematical notation and how it translates to the operations performed in a CNN.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Consider a input tensor $\\mathbf{X}$ with dimension  $3 \\times 3 \\times 3$ (n = 3 and m = 3 channels) and a filter with dimension  $2 \\times 2 \\times 3$ ( windows size with k = 2 and m = 3 channels). The tensors are illustrated in the following figure:\n",
    "\n",
    "<center><img src = \"figures/3d-conv.png\" ></center>\n",
    "\n",
    "\n",
    "The convolution steps for the sliding windows of $\\mathbf{X}$ with the filter $\\mathbf{W}$ illustrated in the figure are:\n",
    "\n",
    "$$\n",
    "\\text{Sum}(\\mathbf{X}_2(1,1) \\odot \\mathbf{W}) = \\text{Sum}\\bigg( \n",
    "\\begin{bmatrix} \n",
    "    \\begin{bmatrix} \n",
    "        1 & -1 \\\\ \n",
    "        2 & 1 \n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix} \n",
    "        2 & 1 \\\\\n",
    "        3 & -1\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix} \n",
    "        1 & -2 \\\\ \n",
    "        2 & 1 \n",
    "    \\end{bmatrix} \n",
    "\\end{bmatrix} \n",
    "\\odot \n",
    "\\begin{bmatrix} \n",
    "    \\begin{bmatrix} \n",
    "        1 & 1 \\\\\n",
    "        2 & 0 \n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix} \n",
    "        1 & 0 \\\\ \n",
    "        0 & 1\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "        0 & 1 \\\\\n",
    "        1 & 0 \n",
    "    \\end{bmatrix} \n",
    "\\end{bmatrix} \\bigg) = \\text{Sum}\\bigg(   \n",
    "    \\begin{bmatrix} \n",
    "    \\begin{bmatrix} \n",
    "        1  & -1  \\\\ \n",
    "        4 & 0 \n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix} \n",
    "        2 & 0 \\\\\n",
    "        0 & -1\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix} \n",
    "        0 & -2 \\\\ \n",
    "        2 & 0 \n",
    "    \\end{bmatrix} \n",
    "\\end{bmatrix} \\bigg) = 1 - 1 + 4 +2 -1 -2+ 2 = 5 \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Sum}(\\mathbf{X}_2(1,2) \\odot \\mathbf{W}) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        -1 & 3 \\\\\n",
    "        1 & -4\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "        1 & 3 \\\\\n",
    "        -1 & 1\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "        -2 & 4 \\\\\n",
    "        1 & -2\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        1 & 1 \\\\\n",
    "        2 & 0\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "        1 & 0 \\\\\n",
    "        0 & 1\n",
    "    \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "        0 & 1 \\\\\n",
    "        1 & 0\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    -1 & 3 \\\\\n",
    "    2 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    0 & 4 \\\\\n",
    "    1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = -1 + 3 + 2 + 1 + 1 + 4 + 1 = 11 \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Sum}(\\mathbf{X}_2(2,1) \\odot \\mathbf{W}) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    2 & 1 \\\\\n",
    "    3 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    3 & -1 \\\\\n",
    "    1 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    2 & 1 \\\\\n",
    "    1 & 3\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    2 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    0 & 1 \\\\\n",
    "    1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    2 & 1 \\\\\n",
    "    6 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    3 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    0 & 1 \\\\\n",
    "    1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = 2 + 1 + 6 + 3 + 1 + 1 + 1 = 15\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Sum}(\\mathbf{X}_2(2,2) \\odot \\mathbf{W}) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    1 & 4 \\\\\n",
    "    1 & 2\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    -1 & 1 \\\\\n",
    "    1 & -2\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    1 & -2 \\\\\n",
    "    3 & -1\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    2 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    0 & 1 \\\\\n",
    "    1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = \\text{Sum}\\bigg(\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    1 & 4 \\\\\n",
    "    2 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    -1 & 0 \\\\\n",
    "    0 & -2\n",
    "\\end{bmatrix} \\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "    0 & -2 \\\\\n",
    "    3 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\bigg) = 1 + 4 +  2 + -1 - 2 - 2 + 3  = 5 \n",
    "$$\n",
    "\n",
    "The convolution $\\mathbf{X}*\\mathbf{W}$ has size $2 \\times 2$, since  $n - k + 1 = 3 - 2 + 1 = 2$, and $m = 3$; it is is given as\n",
    "\n",
    " $$\\mathbf{X}*\\mathbf{W} = \n",
    " \\begin{bmatrix}\n",
    "    \\text{Sum}(\\mathbf{X}_2(1,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{X}_2(1,2) \\odot \\mathbf{W}) \\\\\n",
    "    \\\\\n",
    "    \\text{Sum}(\\mathbf{X}_2(2,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{X}_2(2,2) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    5 & 11 \\\\\n",
    "    15 & 5\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor X:\n",
      " (1, 3, 3, 3, 1)\n",
      "Shape of filter tensor W:\n",
      " (3, 2, 2, 1, 1)\n",
      "Convolved output shape with channel and batch dimension:\n",
      " (1, 1, 2, 2, 1)\n",
      "Convolved output:\n",
      " [[ 5. 11.]\n",
      " [15.  5.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [[1, -1, 3],\n",
    "     [2, 1, 4],\n",
    "     [3, 1, 2]],\n",
    "\n",
    "    [[2, 1, 3],\n",
    "     [3, -1, 1],\n",
    "     [1, 1, -2]],\n",
    "\n",
    "    [[1, -2, 4],\n",
    "     [2, 1, -2],\n",
    "     [1, 3, -1]]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# TensorFlow expects the input to have a shape of [batch, (depth, height, width), channels]\n",
    "# Add a batch dimension and a channel dimension to X\n",
    "X = X.reshape(1, *X.shape, 1) \n",
    "# create a simple 3D kernel\n",
    "W = np.array([\n",
    "    [[1, 1],\n",
    "     [2, 0]],\n",
    "\n",
    "    [[1, 0],\n",
    "     [0, 1]],\n",
    "\n",
    "    [[0, 1],\n",
    "     [1, 0]]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# TensorFlow expects the filter to have a shape of [(depth, height, width), in_channels = 1, out_channels = 1]\n",
    "# Since our input has a single channel (in_channels = 1) and we want a single output channel ( out_channels = 1),\n",
    "# Add those dimensions to W\n",
    "W = W.reshape(*W.shape, 1, 1) \n",
    "\n",
    "# 3D convolution\n",
    "output = tf.nn.conv3d(input=X, filters=W, strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "# squeeze to remove the redundant dimensions of batch and channel\n",
    "output_2d = output.numpy().squeeze()    \n",
    "\n",
    "print(\"Shape of input tensor X:\\n\", X.shape)\n",
    "print(\"Shape of filter tensor W:\\n\", W.shape)\n",
    "print(\"Convolved output shape with channel and batch dimension:\\n\", output.shape)\n",
    "print(\"Convolved output:\\n\", output_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of channels is fixed for both tensors the result of the convolution is a matrix of two dimension, and not a tensor. The matrix from the convolution has dimension $(n-k+1) \\times (n-k+1)$ and can be represented as:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} \\ast \\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "\\text{Sum}(X_k(1,1) \\odot \\mathbf{W})  & \\cdots & \\text{Sum}(X_k(1,n-k+1) \\odot \\mathbf{W}) \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "\\text{Sum}(X_k(n-k+1,1) \\odot \\mathbf{W}) & \\cdots & \\text{Sum}(X_k(n-k+1,n-k+1) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Sum}(\\mathbf{X}_k(i,j) \\odot \\mathbf{W}) = \\sum_{a=1}^{k}\\sum_{b=1}^{k}\\sum_{c=1}^{m}x_{(i+a-1),(j+b-1),~c}~w_{a,b,c}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "for $(i,j) = 1,2, \\cdots, n-k+1$.\n",
    "\n",
    "\n",
    "This process can be visualized as each slice of the filter $\\mathbf{W}$ matching with a corresponding slice in $\\mathbf{X}$, aggregating information across all channels to form a 2D matrix that represents the features extracted from the input tensor $\\mathbf{X}$.\n",
    "\n",
    "In conclusion, the channels of the input tensor $\\mathbf{X}$ represent various features of the input data, and the filter $\\mathbf{W}$ is used to extract these features by convolving it with $\\mathbf{X}$. By using a filter with the same number of channels as the input, each channel's features are processed, allowing the network to learn from each aspect of the input data separately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convolutional Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a CNN, the input tensor is generally denoted as $\\mathbf{X} \\in \\mathbb{R}^{n_0 \\times n_0 \\times m_0}$, where  $n_0 \\times n_0$ represents the spatial dimensions of a 2D input image (e.g., pixels), and $ m_0$ represents the depth, such as 1 for grayscale images or 3 for RGB color images. This input tensor is convolved with multiple filters designed to extract relevant information or features. After convolution, these feature are passed through activation functions within the convolutional layer  $\\mathbf{Z}^1$, which introduce non-linear properties to the model. The process then repeat itself for the subsequent convolutional layers. \n",
    "\n",
    "To exemplify this process, consider two filters $\\mathbf{W}_1$ and $\\mathbf{W}_2$, which convolve with the input tensor $\\mathbf{X}$ to pass the extracted features to the the convolutional layer  $\\mathbf{Z}^1 \\in \\mathbb{R}^{n_1 \\times n_1 \\times m_1}$:\n",
    "\n",
    "\n",
    "<center><img src = \"figures/conv-input-hidden.png\" /></center>\n",
    "\n",
    "Considering a input tensor $\\mathbf{X}$ with spatial dimension $n_0 = 3$ and $m_0 = 3$ channels convolved with two filters $\\mathbf{W}_1$ and $\\mathbf{W}_2$ with window size  $k = 2$, we obtain the output tensor at layer $\\mathbf{Z}^1$. the dimension of $\\mathbf{Z}^1$ is \n",
    "$(n_0 - k + 1) \\times (n_0 - k + 1) \\times m_1$, resulting in a $2 \\times 2 \\times 2$ tensor, where $m_1 = 2$ corresponding to the number of filters applied.\n",
    "\n",
    "Let's incorporate the bias terms $b_1, b_2 \\in \\mathbb{R}$ corresponding to each filter $\\mathbf{W}_1$ and $\\mathbf{W}_2$, and a activation function $f(~ . ~)$. We represent a single  forward step in our simplified visualization of a CNN, going from input to the subsequent layer as:\n",
    "\n",
    "$$\n",
    "{\\mathbf{net}^1}  = \n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        \\text{Sum}(X_2(1,1) \\odot \\mathbf{W}_1)+b_1& \\text{Sum}(X_2(1,2) \\odot \\mathbf{W}_1) +b_1\n",
    "        \\\\\n",
    "        \\\\\n",
    "        \\text{Sum}(X_2(2,1) \\odot \\mathbf{W}_1)+b_1& \\text{Sum}(X_2(2,2) \\odot \\mathbf{W}_1)+b_1\n",
    "    \\end{bmatrix}\\\\\n",
    "    \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "    \\text{Sum}(X_2(1,1)  \\odot \\mathbf{W}_2)+b_2& \\text{Sum}(X_2(1,2) \\odot \\mathbf{W}_2) +b_2\n",
    "    \\\\\n",
    "    \\\\\n",
    "    \\text{Sum}(X_2(2,1) \\odot \\mathbf{W}_2)+b_2& \\text{Sum}(X_2(2,2) \\odot \\mathbf{W}_2)+b_2\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The net signal after convolution is followed by the activation function to introduce non-linearity:\n",
    "\n",
    "$$\n",
    "{\\mathbf{Z}^1} = f(\\mathbf{net}^1) = \n",
    "\\begin{bmatrix}\n",
    "\\\\\n",
    "    \\begin{bmatrix}\n",
    "        f(\\text{Sum}(X_2(1,1) \\odot \\mathbf{W}_1) +b_1)& f(\\text{Sum}(X_2(1,2) \\odot \\mathbf{W}_1)+b_1) \n",
    "        \\\\\n",
    "        \\\\\n",
    "        f(\\text{Sum}(X_2(2,1) \\odot \\mathbf{W}_1)+b_1)& f(\\text{Sum}(X_2(2,2) \\odot \\mathbf{W}_1)+b_1)\n",
    "    \\end{bmatrix}\\\\\n",
    "    \\\\\n",
    "    \\\\\n",
    "    \\begin{bmatrix}\n",
    "    f(\\text{Sum}(X_2(1,1) \\odot \\mathbf{W}_2) + b_2)& f(\\text{Sum}(X_2(1,2) \\odot \\mathbf{W}_2) + b_2)\n",
    "    \\\\\n",
    "    \\\\\n",
    "    f(\\text{Sum}(X_2(2,1) \\odot \\mathbf{W}_2)+ b_2)& f(\\text{Sum}(X_2(2,2) \\odot \\mathbf{W}_2)+ b_2)\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Resulting in the feature map, which represents the actual output of the layer after applying the activation function to the net signal. The activation function can be one commonly used in neural networks, such as identity, sigmoid, tanh, or ReLU. In the language of convolutions, this is simplified as:\n",
    "\n",
    "$$\n",
    "{\\mathbf{Z}^1} = \n",
    "\\begin{bmatrix}\n",
    "    f(\\mathbf{X} * \\mathbf{W}_1 \\oplus b_1)\\\\\n",
    "    \\\\\n",
    "    f(\\mathbf{X} * \\mathbf{W}_2 \\oplus b_2)\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where $\\oplus$ denotes the addition of the bias term to each element of the feature maps produced by $\\mathbf{X} * \\mathbf{W}_1$ and $\\mathbf{X} * \\mathbf{W}_2$. For a compact representation:\n",
    "\n",
    "$$\n",
    "{\\mathbf{Z}^1} = f(\\mathbf{X} * \\mathbf{W}_1 \\oplus b_1,  \\mathbf{X} * \\mathbf{W}_2 \\oplus b_2)\n",
    "$$\n",
    "\n",
    "Extending this concept to a more general and formal case, from the $l$-th layer to the $l+1$-th layer with multiple filters, we denote the tensor at layer $l$ as $\\mathbf{Z}^l \\in \\mathbb{R}^{n_l \\times n_l \\times m_l}$. Each element $Z_{i,j,q}^l$ of the tensor represents the output value of a neuron located at row $i$, column $j$, and channel $q$ for layer $l$, where $1 \\leq (i,j) \\leq n_l$ and $1 \\leq q \\leq m_l$. Assuming we have $m_{l+1}$ filters $\\{\\mathbf{W}_1, \\cdots, \\mathbf{W}_{m_{l+1}}\\}$, the output feature map passed through the next layer will have $m_{l+1}$ channels.\n",
    "\n",
    "The convolution $f(\\mathbf{Z}^l * \\mathbf{W}_q \\oplus b_q)$ for a given filter $q$ produces a feature map matrix of dimension $(n_l-k+1) \\times (n_l-k+1)$, where each element of this feature map corresponds to a neuron's output at layer $l+1$. Convolving $\\mathbf{Z}^l$ with all $m_{l+1}$ filters, we form the tensor $\\mathbf{Z}^{l+1}$ for layer $l+1$ with dimensions $(n_l-k+1) \\times (n_l-k+1) \\times m_{l+1}$. The result for this tensor at layer $l+1$ is:\n",
    "\n",
    "$$\n",
    "{\\mathbf{Z}^{l+1}} = f\\bigg(\\big(\\mathbf{Z}^l * \\mathbf{W}_1 \\oplus b_1\\big), \\cdots,\\big(\\mathbf{Z}^l * \\mathbf{W}_q \\oplus b_q\\big), \\cdots, \\big( \\mathbf{Z}^l * \\mathbf{W}_{m_{l+1}} \\oplus b_{m_{l+1}}\\big)\\bigg)\n",
    "$$\n",
    "\n",
    "In summary, a Convolutional Layer takes as input the $n_l \\times n_l \\times m_l$ tensor  $\\mathbf{Z}^l$ of neurons from layer $l$, and then computes the $n_{l+1} \\times n_{l+1} \\times m_{l+1}$ tensor $\\mathbf{Z}^{l+1}$ of neurons for the next layer $l+1$ via the convolution of $\\mathbf{Z}^{l}$ with $m_{l+1}$ different  filters of size $k \\times k \\times m_l$, followd by adding the bias and applying some non-linear activation function $f(~.~)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Padding and Striding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problem with the convolution operation is that the size of the tensor will decrease in each successive layer. If a tensor $\\mathbf{Z}^l$ at layer $l$ has size $n_l \\times n_l \\times m_l$, and  we use filters of size $k \\times k \\times m_l$, then each channel in a layer $l+1$ will have size $(n_l - (k - 1)) \\times (n_l-(k -1))$. That is, the number of rows and columns for each successive tensor will shrink by $k-1$.\n",
    "\n",
    "\n",
    "**Padding**\n",
    "\n",
    "Padding involves adding zeros or other values around the edges of the input data before applying a convolutional filter. The purpose of padding is to preserve the spatial dimensions of the input data in the output feature map. Without padding, the spatial dimensions of the output feature map would be reduced after each convolutional layer, leading to the loss of important spatial information. By adding padding, the spatial dimensions of the output feature map can be preserved or even increased.\n",
    "\n",
    "Assume that we add $p$ rows and columns of zeros. With padding $p$, the new dimension of tensor $\\mathbf{Z}^l$ at layer $l$ is $(n_l + 2p) \\times (n_l +2p) \\times m_l$. Assuming that each filter is of size $k \\times k \\times m_l$, and that there are $m_{l+1}$ filters, then the size of tensor $\\mathbf{Z}^{l+1}$ at layer $l+1$ will be $(n_l + 2p -(k-1)) \\times (n_l + 2p-(k-1)) \\times m_{l+1}$. Since we want to preserve or increase the size of the resulting tensor, we need to have the following lower bound when choosing the padding:\n",
    "\n",
    "$$n_l +2p - k + 1  \\geq n_l$$\n",
    "\n",
    "which implies $p \\geq \\frac{k-1}{2}$. So the result size after convolution with padding $p$ will be \n",
    "\n",
    "$$Dim(\\mathbf{Z}^{l+1})= (n_l + 2p -(k-1)) \\times (n_l + 2p-(k-1)) \\times m_{l+1}.$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Striding**\n",
    "\n",
    "Striding, on the other hand, involves controls the slide size steps of the filter channels across the sub tensor (or window) of  $\\mathbf{Z}^l$ in the convolution operation. Until now we implicitly use a stride of size $s = 1$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Sum}(\\mathbf{Z}^l_k(i,j) \\odot \\mathbf{W})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "for $(i,j) = 1,2, \\cdots, n_l-k+1$, where the indices $i$ and $j$ increase by $s = 1$ at each step. For a given stride $s$, the set of indices $(i,j)$ can be written as:\n",
    "\n",
    "$$\n",
    "\\text{for stride } s, \\quad (i,j) = 1 + 0\\cdot s,1+1 \\cdot s,1+2\\cdot s, \\cdots,1 + t\\cdot s\n",
    "$$\n",
    "\n",
    "where $t$ is the largest integer such that $1 + ts \\leq n_l - k + 1$. This ensures that the applied filter starting from the first element and slide it over the matrix by $s$ elements each time, stopping at the correct boundary without exceeding the size of the window matrix. this results in \n",
    "\n",
    "$$\n",
    "t \\leq \\left\\lfloor \\frac{n_l - k}{s} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "the symbol $\\lfloor ~ \\rfloor$ means rounding down to the nearest whole number (since we cannot have a fraction of a step).\n",
    "\n",
    "Taking the convolution of $\\mathbf{Z}^l$ with size $n_l \\times n_l \\times m_l$ with a filter $\\mathbf{W}$ of size $k \\times k \\times m_l$ and stride $s \\geq 1$ would give:\n",
    "\n",
    "$$\\mathbf{Z}^l\\ast \\mathbf{W} = \\begin{bmatrix}\n",
    "\\text{Sum}(\\mathbf{Z}^l_k(1,1) \\odot \\mathbf{W}) &\\text{Sum}(\\mathbf{Z}^l_k(1,1+s) \\odot \\mathbf{W}) & \\cdots & \\text{Sum}(\\mathbf{Z}^l_k(1,1+t.s) \\odot \\mathbf{W}) \\\\\n",
    "\\text{Sum}(\\mathbf{Z}^l_k(1+s,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{Z}^l_k(1+s,1+s) \\odot \\mathbf{W}) & \\cdots &\\text{Sum}(\\mathbf{Z}^l_k(1+s,1+t.s) \\odot \\mathbf{W})\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Sum}(\\mathbf{Z}^l_k(1+t.s,1) \\odot \\mathbf{W}) & \\text{Sum}(\\mathbf{Z}^l_k(1+t.s,1+s) \\odot \\mathbf{W}) & \\cdots & \\text{Sum}(\\mathbf{Z}^l_k(1+t.s,1+t.s) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where $t \\leq \\left\\lfloor \\frac{n_l - k}{s} \\right\\rfloor$. So, the result dimension after convolution with striding $s$ for a set of $m_{l+1}$ filters will be\n",
    "\n",
    "$$Dim(\\mathbf{Z}^{l+1})= \\bigg(\\left\\lfloor \\frac{n_l - k}{s} \\right\\rfloor + 1\\bigg) \\times \\bigg(\\left\\lfloor \\frac{n_l - k}{s} \\right\\rfloor + 1\\bigg) \\times m_{l+1}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Max-pooling Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we replace the summation with the maximum value over the element-wise product of $\\mathbf{{Z}_k^l}$ and $\\mathbf{W}$, we get\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Sum}(\\mathbf{Z}_k(i,j) \\odot \\mathbf{W}) &\\longrightarrow \\text{Max}(\\mathbf{Z}_k(i,j))\\\\\n",
    "\\\\\n",
    "\\sum_{a=1}^{k}\\sum_{b=1}^{k}\\sum_{c=1}^{m_l}z^l_{(i+a-1),(j+b-1),~c}~w_{a,b,c} &~\\longrightarrow \n",
    "\\max_{\\substack{a ~= 1,\\cdots,k \\\\ b~ = 1,\\cdots,k \\\\ c = 1,\\cdots,m_l}}{\\bigg\\{z^l_{(i+a-1),(j+b-1),~c}~\\cdot w_{a,b,c} \\bigg\\}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The convolution of $\\mathbf{Z}^l \\in \\mathbb{R}^{n_l \\times n_l \\times m_l}$ with filter $\\mathbf{W} \\in \\mathbb{R}^{k \\times k \\times 1}$ using max-pooling, denoted $\\mathbf{Z}^l \\ast_{max} ~ \\mathbf{W}$, restuls in a $(n_l -k +1) \\times (n_l -k+1) \\times 1$ (for a single filter) is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{Z}_k^l \\ast_{max} \\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "\\text{Max}(Z^l_k(1,1) \\odot \\mathbf{W})  & \\cdots & \\text{Max}(Z^l_k(1,n-k+1) \\odot \\mathbf{W}) \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "\\text{Max}(Z^l_k(n-k+1,1) \\odot \\mathbf{W}) & \\cdots & \\text{Max}(Z^l_k(n-k+1,n-k+1) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Typically, max-pooling its common to set the stride equal to the filter size ($s = k$), so that the aggregation function is applied over disjoint $k \\times k$ windows in each channel in $\\mathbf{Z}^l$. In pooling layer, a filter $\\mathbf{W}$ is by default a $k \\times k \\times 1$ tensor of fixed value of ones, so that $\\mathbf{W} = \\mathbf{1}_{k \\times k \\times 1} $. This means that the filters will not be updated during the backpropagation. Also, the filters has no bias term, they all are fixed as zeros. The convolution of $\\mathbf{Z}^l \\in \\mathbb{R}^{n_l \\times n_l \\times m_l}$ with  $\\mathbf{W} \\in \\mathbb{R}^{k \\times k \\times 1}$ , using stride $s = k$, results in  a tensor $\\mathbf{Z}^{l+1}$ of size $\\left\\lfloor \\frac{n_l}{k} \\right\\rfloor \\times \\left\\lfloor \\frac{n_l}{k} \\right\\rfloor \\times m_l$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{Z}^{l+1} = \\mathbf{Z}_k^l \\ast_{max} \\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "\\text{Max}(Z^l_k(1,1) \\odot \\mathbf{W})  & \\cdots & \\text{Max}(Z^l_k(1,\\left\\lfloor \\frac{n_l}{k} \\right\\rfloor ) \\odot \\mathbf{W}) \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "\\text{Max}(Z^l_k(\\left\\lfloor \\frac{n_l}{k} \\right\\rfloor,1) \\odot \\mathbf{W}) & \\cdots & \\text{Max}(Z^l_k(\\left\\lfloor \\frac{n_l}{k} \\right\\rfloor,\\left\\lfloor \\frac{n_l}{k} \\right\\rfloor) \\odot \\mathbf{W})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that the max pooling layer do not uses any activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training CNNs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN for Classification (Python Code)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 nn_model, \n",
    "                 img_shape: tuple = (150, 150, 3), \n",
    "                 filters: list = [32], \n",
    "                 filter_size: list = [(3, 3)], \n",
    "                 pool_sizes: list = [(2, 2)], \n",
    "                 activation: str = 'relu', \n",
    "                 filter_initializer: str = 'glorot_uniform') -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the CNN class.\n",
    "\n",
    "        Parameters:\n",
    "        nn_model (Model): An instance of a model that will receive the flattened features for final classification.\n",
    "        img_shape (tuple): The shape of the input image.\n",
    "        filters (list): A list specifying the number of filters in each convolutional layer.\n",
    "        filter_size (list): A list specifying the dimensions of the filters in each convolutional layer.\n",
    "        pool_sizes (list): A list specifying the dimensions of the pooling window for each maxpooling layer.\n",
    "        activation (str): The activation function applied to each convolutional layer.\n",
    "        filter_initializer (str): The initializer for the filters of the convolutional layers.\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        self.nn_model = nn_model\n",
    "        self.img_shape = img_shape\n",
    "        self.filters = filters\n",
    "        self.filter_size = filter_size\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.activation = activation\n",
    "        self.filter_initializer = filter_initializer\n",
    "\n",
    "        # create convolutional layers\n",
    "        self.conv2d = []\n",
    "        for i in range(len(filters)):\n",
    "            self.conv2d.append( Conv2D( filters = self.filters[i], \n",
    "                                        kernel_size = self.filter_size[i], \n",
    "                                        kernel_initializer = self.filter_initializer,\n",
    "                                        input_shape = img_shape, \n",
    "                                        activation = self.activation, \n",
    "                                        name='Conv2D_{}'.format(i)))\n",
    "\n",
    "        # create maxpooling layers\n",
    "        self.maxpool = []\n",
    "        for i in range(len(self.pool_sizes)):\n",
    "            self.maxpool.append( MaxPool2D( pool_size=self.pool_sizes[i],\n",
    "                                            name='MaxPool_{}'.format(i)))\n",
    "\n",
    "\n",
    "        # create flatten layer to feed into the dense layer \n",
    "        self.flatten = Flatten(name='Flatten')\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Parameters:\n",
    "        x (Tensor): The input tensor containing the image data.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The output tensor after applying the convolutional and pooling layers, and the final model.\n",
    "        \"\"\"\n",
    "        for conv_layer, maxpool_layer in zip(self.conv2d, self.maxpool):\n",
    "            x = conv_layer(x)\n",
    "            x = maxpool_layer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.nn_model(x)\n",
    "        return x\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Builds the CNN model by setting up the input layer and invoking the call method for the graph.\n",
    "\n",
    "        Returns:\n",
    "        Model: The fully constructed CNN model.\n",
    "        \"\"\"\n",
    "        x = Input(shape=self.img_shape, name=\"Input\")\n",
    "        model = Model(inputs=x, outputs=self.call(x), name=\"CNN\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes: list = [64],\n",
    "        output_size: int = 1,\n",
    "        output_activation: str = \"sigmoid\",\n",
    "        activation: str = \"relu\",\n",
    "        weight_initializer: str = \"glorot_uniform\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the NN class.\n",
    "\n",
    "        Parameters:\n",
    "        layer_sizes (list): A list indicating the size of each dense layer.\n",
    "        output_size (int): The number of units in the output layer.\n",
    "        output_activation (str): The activation function for the output layer.\n",
    "        activation (str): The activation function for all hidden layers.\n",
    "        initializer (str): The initializer for the weights in all layers.\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__(name = 'Dense')\n",
    "\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.output_size = output_size\n",
    "        self.activation_func = activation\n",
    "        self.output_activation = output_activation\n",
    "        self.weight_initializer = weight_initializer\n",
    "\n",
    "        # Hidden Layers\n",
    "        self.hidden_layer = []\n",
    "        for i in range(len(layer_sizes)):\n",
    "            self.hidden_layer.append(Dense( units = self.layer_sizes[i], \n",
    "                                            kernel_initializer = self.weight_initializer,\n",
    "                                            activation = activation, name='Dense_{}'.format(i)))\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = Dense( units= self.output_size,\n",
    "                                    kernel_initializer = self.weight_initializer,\n",
    "                                    activation=output_activation,\n",
    "                                    name=\"Output\" )\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the network, processing the input through each hidden layer followed by the output layer.\n",
    "\n",
    "        Parameters:\n",
    "        x (tf.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "        tf.Tensor: The resulting tensor after passing through all layers of the network.\n",
    "        \"\"\"\n",
    "        for hidden in self.hidden_layer:\n",
    "            x = hidden(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "* `mean squared error`\n",
    "* **`binary crossentropy`**\n",
    "* `categorical crossentropy`\n",
    "* `cosine similarity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that. \n",
    "\n",
    "* 1 \n",
    "* 65\n",
    "* 896\n",
    "* **11214912**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " Conv2D_0 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " MaxPool_0 (MaxPooling2D)    (None, 74, 74, 32)        0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " Dense (NN)                  (None, 1)                 11214977  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = NN()\n",
    "cnn_model = CNN(nn_model).build()\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(cnn_model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generators and Training**\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x150>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image resized to 150x150 pixels and 3 color channels\n",
    "img_path = 'data/train/bee/42057180260_98f4ae9345_n.jpg'\n",
    "img_actual = load_img(img_path)\n",
    "img_resize = load_img(img_path, target_size = (150, 150))\n",
    "img_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual size: (213, 320, 3)\n",
      "after resize for input of the CNN: (150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Input size for the CNN\n",
    "actual_size = np.array(img_actual).shape\n",
    "input_size = np.array(img_resize).shape\n",
    "\n",
    "print('actual size:', actual_size)\n",
    "print('after resize for input of the CNN:', input_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Classes for binary classification: {'bee': 0, 'wasp': 1}\n"
     ]
    }
   ],
   "source": [
    "# reescale the image pixels to the range [0, 1]\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_path = 'data/train'\n",
    "test_path = 'data/test'\n",
    "\n",
    "# Set up the train and test generators\n",
    "train_batch_gen = train_data_gen.flow_from_directory( train_path,\n",
    "                                          target_size = (150, 150),\n",
    "                                          batch_size = 20,\n",
    "                                          class_mode = 'binary',\n",
    "                                          shuffle = True,)\n",
    "\n",
    "test_batch_gen = test_data_gen.flow_from_directory( test_path,\n",
    "                                        target_size = (150, 150),\n",
    "                                        batch_size = 20,\n",
    "                                        class_mode = 'binary',\n",
    "                                        shuffle = True,)\n",
    "\n",
    "print('Classes for binary classification:', train_batch_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.20\n",
    "* 0.40\n",
    "* 0.60\n",
    "* **0.80**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 10s 51ms/step - loss: 0.6665 - accuracy: 0.5915 - val_loss: 0.6100 - val_accuracy: 0.6656\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.6008 - accuracy: 0.6717 - val_loss: 0.5858 - val_accuracy: 0.6645\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.5495 - accuracy: 0.7302 - val_loss: 0.5514 - val_accuracy: 0.7375\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.5158 - accuracy: 0.7536 - val_loss: 0.5266 - val_accuracy: 0.7473\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.4877 - accuracy: 0.7718 - val_loss: 0.5578 - val_accuracy: 0.7092\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.4530 - accuracy: 0.7963 - val_loss: 0.5156 - val_accuracy: 0.7571\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.4434 - accuracy: 0.8012 - val_loss: 0.5045 - val_accuracy: 0.7691\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.3993 - accuracy: 0.8287 - val_loss: 0.5321 - val_accuracy: 0.7582\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 9s 51ms/step - loss: 0.3732 - accuracy: 0.8420 - val_loss: 0.4914 - val_accuracy: 0.7702\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 9s 50ms/step - loss: 0.3380 - accuracy: 0.8646 - val_loss: 0.5014 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with binary crossentropy loss and the Adam optimizer\n",
    "optimizer = SGD(learning_rate=0.002, momentum=0.8)\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = cnn_model.fit( train_batch_gen,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median accuracy on train set: 0.784\n"
     ]
    }
   ],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "print(\"median accuracy on train set:\", round(np.median(accuracy), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.031\n",
    "* 0.061\n",
    "* **0.091**\n",
    "* 0.131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of loss on train set: 0.098\n"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "print(\"Standard Deviation of loss on train set:\", round(np.std(loss), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Augmentation**\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to the training data generator:\n",
    "\n",
    "* `rotation_range=50,`\n",
    "* `width_shift_range=0.1,`\n",
    "* `height_shift_range=0.1,`\n",
    "* `zoom_range=0.1,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation is a technique used to artificially expand the size of a training dataset\n",
    "# The test set is unchanged because they are used as a reference to evaluate the model\n",
    "train_data_aug = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rescale=1./255)\n",
    "\n",
    "train_batch_aug = train_data_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 5** \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "> **Note:** make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.18\n",
    "* **0.48**\n",
    "* 0.78\n",
    "* 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 25s 136ms/step - loss: 0.4973 - accuracy: 0.7645 - val_loss: 0.5101 - val_accuracy: 0.7636\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 25s 135ms/step - loss: 0.4832 - accuracy: 0.7745 - val_loss: 0.5005 - val_accuracy: 0.7691\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4833 - accuracy: 0.7794 - val_loss: 0.4637 - val_accuracy: 0.7854\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4749 - accuracy: 0.7808 - val_loss: 0.5277 - val_accuracy: 0.7331\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4776 - accuracy: 0.7846 - val_loss: 0.4753 - val_accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 25s 136ms/step - loss: 0.4676 - accuracy: 0.7871 - val_loss: 0.4652 - val_accuracy: 0.7789\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 25s 138ms/step - loss: 0.4646 - accuracy: 0.7930 - val_loss: 0.4502 - val_accuracy: 0.7865\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4569 - accuracy: 0.7925 - val_loss: 0.4597 - val_accuracy: 0.7898\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4499 - accuracy: 0.7922 - val_loss: 0.5034 - val_accuracy: 0.7800\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.4601 - accuracy: 0.7892 - val_loss: 0.4614 - val_accuracy: 0.7941\n"
     ]
    }
   ],
   "source": [
    "augmented_history = cnn_model.fit( train_batch_aug,\n",
    "                                   epochs = 10,\n",
    "                                   validation_data = test_batch_gen )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss of test set: 0.538\n"
     ]
    }
   ],
   "source": [
    "val_loss = history.history['val_loss']\n",
    "print(\"Mean loss of test set:\", round(np.mean(val_loss), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 6**\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.38\n",
    "* 0.58\n",
    "* **0.78**\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for last 5 Epochs on test set: 0.764\n"
     ]
    }
   ],
   "source": [
    "last_five_accuracy = history.history['val_accuracy'][-5:]\n",
    "print(\"Average Accuracy for last 5 epochs on test set:\", round(np.average(last_five_accuracy), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
